{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPN4DOo80RVdDbJ2kBmDPjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borricha/-PyTorchZeroToAll/blob/main/lec_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2y87UtDBckC",
        "outputId": "37575bf9-e000-4759-e045-fac26f67b611"
      },
      "source": [
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        "\n",
        "\n",
        "w = 1.0\n",
        "\n",
        "def forward(x):\n",
        "   return x * w\n",
        "\n",
        "def loss(x, y):\n",
        "  y_pred = forward(x)\n",
        "  return (y_pred - y) ** 2\n",
        "\n",
        "def gradient(x,y ):\n",
        "   return 2 * x * (w * x -y)\n",
        "\n",
        "print(\"predict (before training)\", 4, forward(4))\n",
        "for epoch in range(200):\n",
        "  for x_val, y_val in zip(x_data, y_data):\n",
        "    grad = gradient(x_val,y_val)\n",
        "    w -= 0.01 * grad\n",
        "    print(\"\\t grad: \", x_val, y_val, grad)\n",
        "    l = loss(x_val,y_val)\n",
        "  print(\"progress:\", epoch, \"w= \",w, \"loss= \", l)\n",
        "\n",
        "print(\"predict (after training)\", \"4hours\", forward(4))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (befor training) 4 4.0\n",
            "\t grad:  1.0 2.0 -2.0\n",
            "\t grad:  2.0 4.0 -7.84\n",
            "\t grad:  3.0 6.0 -16.2288\n",
            "progress: 0 w=  1.260688 loss=  4.919240100095999\n",
            "\t grad:  1.0 2.0 -1.478624\n",
            "\t grad:  2.0 4.0 -5.796206079999999\n",
            "\t grad:  3.0 6.0 -11.998146585599997\n",
            "progress: 1 w=  1.453417766656 loss=  2.688769240265834\n",
            "\t grad:  1.0 2.0 -1.093164466688\n",
            "\t grad:  2.0 4.0 -4.285204709416961\n",
            "\t grad:  3.0 6.0 -8.87037374849311\n",
            "progress: 2 w=  1.5959051959019805 loss=  1.4696334962911515\n",
            "\t grad:  1.0 2.0 -0.8081896081960389\n",
            "\t grad:  2.0 4.0 -3.1681032641284723\n",
            "\t grad:  3.0 6.0 -6.557973756745939\n",
            "progress: 3 w=  1.701247862192685 loss=  0.8032755585999681\n",
            "\t grad:  1.0 2.0 -0.59750427561463\n",
            "\t grad:  2.0 4.0 -2.3422167604093502\n",
            "\t grad:  3.0 6.0 -4.848388694047353\n",
            "progress: 4 w=  1.7791289594933983 loss=  0.43905614881022015\n",
            "\t grad:  1.0 2.0 -0.44174208101320334\n",
            "\t grad:  2.0 4.0 -1.7316289575717576\n",
            "\t grad:  3.0 6.0 -3.584471942173538\n",
            "progress: 5 w=  1.836707389300983 loss=  0.2399802903801062\n",
            "\t grad:  1.0 2.0 -0.3265852213980338\n",
            "\t grad:  2.0 4.0 -1.2802140678802925\n",
            "\t grad:  3.0 6.0 -2.650043120512205\n",
            "progress: 6 w=  1.8792758133988885 loss=  0.1311689630744999\n",
            "\t grad:  1.0 2.0 -0.241448373202223\n",
            "\t grad:  2.0 4.0 -0.946477622952715\n",
            "\t grad:  3.0 6.0 -1.9592086795121197\n",
            "progress: 7 w=  1.910747160155559 loss=  0.07169462478267678\n",
            "\t grad:  1.0 2.0 -0.17850567968888198\n",
            "\t grad:  2.0 4.0 -0.6997422643804168\n",
            "\t grad:  3.0 6.0 -1.4484664872674653\n",
            "progress: 8 w=  1.9340143044689266 loss=  0.03918700813247573\n",
            "\t grad:  1.0 2.0 -0.13197139106214673\n",
            "\t grad:  2.0 4.0 -0.5173278529636143\n",
            "\t grad:  3.0 6.0 -1.0708686556346834\n",
            "progress: 9 w=  1.9512159834655312 loss=  0.021418922423117836\n",
            "\t grad:  1.0 2.0 -0.09756803306893769\n",
            "\t grad:  2.0 4.0 -0.38246668963023644\n",
            "\t grad:  3.0 6.0 -0.7917060475345892\n",
            "progress: 10 w=  1.9639333911678687 loss=  0.01170720245384975\n",
            "\t grad:  1.0 2.0 -0.07213321766426262\n",
            "\t grad:  2.0 4.0 -0.2827622132439096\n",
            "\t grad:  3.0 6.0 -0.5853177814148953\n",
            "progress: 11 w=  1.9733355232910992 loss=  0.006398948863435593\n",
            "\t grad:  1.0 2.0 -0.05332895341780164\n",
            "\t grad:  2.0 4.0 -0.2090494973977819\n",
            "\t grad:  3.0 6.0 -0.4327324596134101\n",
            "progress: 12 w=  1.9802866323953892 loss=  0.003497551760830656\n",
            "\t grad:  1.0 2.0 -0.039426735209221686\n",
            "\t grad:  2.0 4.0 -0.15455280202014876\n",
            "\t grad:  3.0 6.0 -0.3199243001817109\n",
            "progress: 13 w=  1.9854256707695 loss=  0.001911699652671057\n",
            "\t grad:  1.0 2.0 -0.02914865846100012\n",
            "\t grad:  2.0 4.0 -0.11426274116712065\n",
            "\t grad:  3.0 6.0 -0.2365238742159388\n",
            "progress: 14 w=  1.9892250235079405 loss=  0.0010449010656399273\n",
            "\t grad:  1.0 2.0 -0.021549952984118992\n",
            "\t grad:  2.0 4.0 -0.08447581569774698\n",
            "\t grad:  3.0 6.0 -0.17486493849433593\n",
            "progress: 15 w=  1.9920339305797026 loss=  0.0005711243580809696\n",
            "\t grad:  1.0 2.0 -0.015932138840594856\n",
            "\t grad:  2.0 4.0 -0.062453984255132156\n",
            "\t grad:  3.0 6.0 -0.12927974740812687\n",
            "progress: 16 w=  1.994110589284741 loss=  0.0003121664271570621\n",
            "\t grad:  1.0 2.0 -0.011778821430517894\n",
            "\t grad:  2.0 4.0 -0.046172980007630926\n",
            "\t grad:  3.0 6.0 -0.09557806861579543\n",
            "progress: 17 w=  1.9956458879852805 loss=  0.0001706246229305199\n",
            "\t grad:  1.0 2.0 -0.008708224029438938\n",
            "\t grad:  2.0 4.0 -0.03413623819540135\n",
            "\t grad:  3.0 6.0 -0.07066201306448505\n",
            "progress: 18 w=  1.9967809527381737 loss=  9.326038746484765e-05\n",
            "\t grad:  1.0 2.0 -0.006438094523652627\n",
            "\t grad:  2.0 4.0 -0.02523733053271826\n",
            "\t grad:  3.0 6.0 -0.052241274202728505\n",
            "progress: 19 w=  1.9976201197307648 loss=  5.097447086306101e-05\n",
            "\t grad:  1.0 2.0 -0.004759760538470381\n",
            "\t grad:  2.0 4.0 -0.01865826131080439\n",
            "\t grad:  3.0 6.0 -0.03862260091336722\n",
            "progress: 20 w=  1.998240525958391 loss=  2.7861740127856012e-05\n",
            "\t grad:  1.0 2.0 -0.0035189480832178432\n",
            "\t grad:  2.0 4.0 -0.01379427648621423\n",
            "\t grad:  3.0 6.0 -0.028554152326460525\n",
            "progress: 21 w=  1.99869919972735 loss=  1.5228732143933469e-05\n",
            "\t grad:  1.0 2.0 -0.002601600545300009\n",
            "\t grad:  2.0 4.0 -0.01019827413757568\n",
            "\t grad:  3.0 6.0 -0.021110427464781978\n",
            "progress: 22 w=  1.9990383027488265 loss=  8.323754426231206e-06\n",
            "\t grad:  1.0 2.0 -0.001923394502346909\n",
            "\t grad:  2.0 4.0 -0.007539706449199102\n",
            "\t grad:  3.0 6.0 -0.01560719234984198\n",
            "progress: 23 w=  1.9992890056818404 loss=  4.549616284094891e-06\n",
            "\t grad:  1.0 2.0 -0.0014219886363191492\n",
            "\t grad:  2.0 4.0 -0.005574195454370212\n",
            "\t grad:  3.0 6.0 -0.011538584590544687\n",
            "progress: 24 w=  1.999474353368653 loss=  2.486739429417538e-06\n",
            "\t grad:  1.0 2.0 -0.0010512932626940419\n",
            "\t grad:  2.0 4.0 -0.004121069589761106\n",
            "\t grad:  3.0 6.0 -0.008530614050808794\n",
            "progress: 25 w=  1.9996113831376856 loss=  1.3592075910762856e-06\n",
            "\t grad:  1.0 2.0 -0.0007772337246287897\n",
            "\t grad:  2.0 4.0 -0.0030467562005451754\n",
            "\t grad:  3.0 6.0 -0.006306785335127074\n",
            "progress: 26 w=  1.9997126908902887 loss=  7.429187207079447e-07\n",
            "\t grad:  1.0 2.0 -0.0005746182194226179\n",
            "\t grad:  2.0 4.0 -0.002252503420136165\n",
            "\t grad:  3.0 6.0 -0.00466268207967957\n",
            "progress: 27 w=  1.9997875889274812 loss=  4.060661735575354e-07\n",
            "\t grad:  1.0 2.0 -0.0004248221450375844\n",
            "\t grad:  2.0 4.0 -0.0016653028085471533\n",
            "\t grad:  3.0 6.0 -0.0034471768136938863\n",
            "progress: 28 w=  1.9998429619451539 loss=  2.2194855602869353e-07\n",
            "\t grad:  1.0 2.0 -0.00031407610969225175\n",
            "\t grad:  2.0 4.0 -0.0012311783499932005\n",
            "\t grad:  3.0 6.0 -0.0025485391844828342\n",
            "progress: 29 w=  1.9998838998815958 loss=  1.213131374411496e-07\n",
            "\t grad:  1.0 2.0 -0.00023220023680847746\n",
            "\t grad:  2.0 4.0 -0.0009102249282886277\n",
            "\t grad:  3.0 6.0 -0.0018841656015560204\n",
            "progress: 30 w=  1.9999141657892625 loss=  6.630760559646474e-08\n",
            "\t grad:  1.0 2.0 -0.00017166842147497974\n",
            "\t grad:  2.0 4.0 -0.0006729402121816719\n",
            "\t grad:  3.0 6.0 -0.0013929862392156878\n",
            "progress: 31 w=  1.9999365417379913 loss=  3.624255915449335e-08\n",
            "\t grad:  1.0 2.0 -0.0001269165240174175\n",
            "\t grad:  2.0 4.0 -0.0004975127741477792\n",
            "\t grad:  3.0 6.0 -0.0010298514424817995\n",
            "progress: 32 w=  1.9999530845453979 loss=  1.9809538924707548e-08\n",
            "\t grad:  1.0 2.0 -9.383090920422887e-05\n",
            "\t grad:  2.0 4.0 -0.00036781716408107457\n",
            "\t grad:  3.0 6.0 -0.0007613815296476645\n",
            "progress: 33 w=  1.9999653148414271 loss=  1.0827542027017377e-08\n",
            "\t grad:  1.0 2.0 -6.937031714571162e-05\n",
            "\t grad:  2.0 4.0 -0.0002719316432120422\n",
            "\t grad:  3.0 6.0 -0.0005628985014531906\n",
            "progress: 34 w=  1.999974356846045 loss=  5.9181421028034105e-09\n",
            "\t grad:  1.0 2.0 -5.1286307909848006e-05\n",
            "\t grad:  2.0 4.0 -0.00020104232700646207\n",
            "\t grad:  3.0 6.0 -0.0004161576169003922\n",
            "progress: 35 w=  1.9999810417085633 loss=  3.2347513278475087e-09\n",
            "\t grad:  1.0 2.0 -3.7916582873442906e-05\n",
            "\t grad:  2.0 4.0 -0.0001486330048638962\n",
            "\t grad:  3.0 6.0 -0.0003076703200690645\n",
            "progress: 36 w=  1.9999859839076413 loss=  1.7680576050779005e-09\n",
            "\t grad:  1.0 2.0 -2.8032184717474706e-05\n",
            "\t grad:  2.0 4.0 -0.0001098861640933535\n",
            "\t grad:  3.0 6.0 -0.00022746435967313516\n",
            "progress: 37 w=  1.9999896377347262 loss=  9.6638887447731e-10\n",
            "\t grad:  1.0 2.0 -2.0724530547688857e-05\n",
            "\t grad:  2.0 4.0 -8.124015974608767e-05\n",
            "\t grad:  3.0 6.0 -0.00016816713067413502\n",
            "progress: 38 w=  1.999992339052936 loss=  5.282109892545845e-10\n",
            "\t grad:  1.0 2.0 -1.5321894128117464e-05\n",
            "\t grad:  2.0 4.0 -6.006182498197177e-05\n",
            "\t grad:  3.0 6.0 -0.00012432797771566584\n",
            "progress: 39 w=  1.9999943361699042 loss=  2.887107421958329e-10\n",
            "\t grad:  1.0 2.0 -1.1327660191629008e-05\n",
            "\t grad:  2.0 4.0 -4.4404427951505454e-05\n",
            "\t grad:  3.0 6.0 -9.191716585732479e-05\n",
            "progress: 40 w=  1.9999958126624442 loss=  1.5780416225633037e-10\n",
            "\t grad:  1.0 2.0 -8.37467511161094e-06\n",
            "\t grad:  2.0 4.0 -3.282872643772805e-05\n",
            "\t grad:  3.0 6.0 -6.795546372551087e-05\n",
            "progress: 41 w=  1.999996904251097 loss=  8.625295142578772e-11\n",
            "\t grad:  1.0 2.0 -6.191497806007362e-06\n",
            "\t grad:  2.0 4.0 -2.4270671399762023e-05\n",
            "\t grad:  3.0 6.0 -5.0240289795056015e-05\n",
            "progress: 42 w=  1.999997711275687 loss=  4.71443308235547e-11\n",
            "\t grad:  1.0 2.0 -4.5774486259198e-06\n",
            "\t grad:  2.0 4.0 -1.794359861406747e-05\n",
            "\t grad:  3.0 6.0 -3.714324913239864e-05\n",
            "progress: 43 w=  1.9999983079186507 loss=  2.5768253628059826e-11\n",
            "\t grad:  1.0 2.0 -3.3841626985164908e-06\n",
            "\t grad:  2.0 4.0 -1.326591777761621e-05\n",
            "\t grad:  3.0 6.0 -2.7460449796734565e-05\n",
            "progress: 44 w=  1.9999987490239537 loss=  1.4084469615916932e-11\n",
            "\t grad:  1.0 2.0 -2.5019520926150562e-06\n",
            "\t grad:  2.0 4.0 -9.807652203264183e-06\n",
            "\t grad:  3.0 6.0 -2.0301840059744336e-05\n",
            "progress: 45 w=  1.9999990751383971 loss=  7.698320862431846e-12\n",
            "\t grad:  1.0 2.0 -1.8497232057157476e-06\n",
            "\t grad:  2.0 4.0 -7.250914967116273e-06\n",
            "\t grad:  3.0 6.0 -1.5009393983689279e-05\n",
            "progress: 46 w=  1.9999993162387186 loss=  4.20776540913866e-12\n",
            "\t grad:  1.0 2.0 -1.3675225627451937e-06\n",
            "\t grad:  2.0 4.0 -5.3606884460322135e-06\n",
            "\t grad:  3.0 6.0 -1.109662508014253e-05\n",
            "progress: 47 w=  1.9999994944870796 loss=  2.299889814334344e-12\n",
            "\t grad:  1.0 2.0 -1.0110258408246864e-06\n",
            "\t grad:  2.0 4.0 -3.963221296032771e-06\n",
            "\t grad:  3.0 6.0 -8.20386808086937e-06\n",
            "progress: 48 w=  1.9999996262682318 loss=  1.2570789110540446e-12\n",
            "\t grad:  1.0 2.0 -7.474635363990956e-07\n",
            "\t grad:  2.0 4.0 -2.930057062755509e-06\n",
            "\t grad:  3.0 6.0 -6.065218119744031e-06\n",
            "progress: 49 w=  1.999999723695619 loss=  6.870969979249939e-13\n",
            "\t grad:  1.0 2.0 -5.526087618612507e-07\n",
            "\t grad:  2.0 4.0 -2.166226346744793e-06\n",
            "\t grad:  3.0 6.0 -4.484088535150477e-06\n",
            "progress: 50 w=  1.9999997957248556 loss=  3.7555501141274804e-13\n",
            "\t grad:  1.0 2.0 -4.08550288710785e-07\n",
            "\t grad:  2.0 4.0 -1.6015171322436572e-06\n",
            "\t grad:  3.0 6.0 -3.3151404608133817e-06\n",
            "progress: 51 w=  1.9999998489769344 loss=  2.052716967104274e-13\n",
            "\t grad:  1.0 2.0 -3.020461312175371e-07\n",
            "\t grad:  2.0 4.0 -1.1840208351543424e-06\n",
            "\t grad:  3.0 6.0 -2.4509231284497446e-06\n",
            "progress: 52 w=  1.9999998883468353 loss=  1.1219786256679713e-13\n",
            "\t grad:  1.0 2.0 -2.2330632942768602e-07\n",
            "\t grad:  2.0 4.0 -8.753608113920563e-07\n",
            "\t grad:  3.0 6.0 -1.811996877876254e-06\n",
            "progress: 53 w=  1.9999999174534755 loss=  6.132535848018759e-14\n",
            "\t grad:  1.0 2.0 -1.6509304900935717e-07\n",
            "\t grad:  2.0 4.0 -6.471647520100987e-07\n",
            "\t grad:  3.0 6.0 -1.3396310407642886e-06\n",
            "progress: 54 w=  1.999999938972364 loss=  3.351935118167793e-14\n",
            "\t grad:  1.0 2.0 -1.220552721115098e-07\n",
            "\t grad:  2.0 4.0 -4.784566662863199e-07\n",
            "\t grad:  3.0 6.0 -9.904052991061008e-07\n",
            "progress: 55 w=  1.9999999548815364 loss=  1.8321081844499955e-14\n",
            "\t grad:  1.0 2.0 -9.023692726373156e-08\n",
            "\t grad:  2.0 4.0 -3.5372875473171916e-07\n",
            "\t grad:  3.0 6.0 -7.322185204827747e-07\n",
            "progress: 56 w=  1.9999999666433785 loss=  1.0013977760018664e-14\n",
            "\t grad:  1.0 2.0 -6.671324292994996e-08\n",
            "\t grad:  2.0 4.0 -2.615159129248923e-07\n",
            "\t grad:  3.0 6.0 -5.413379398078177e-07\n",
            "progress: 57 w=  1.9999999753390494 loss=  5.473462367088053e-15\n",
            "\t grad:  1.0 2.0 -4.932190122985958e-08\n",
            "\t grad:  2.0 4.0 -1.9334185274999527e-07\n",
            "\t grad:  3.0 6.0 -4.002176350326181e-07\n",
            "progress: 58 w=  1.9999999817678633 loss=  2.991697274308627e-15\n",
            "\t grad:  1.0 2.0 -3.6464273378555845e-08\n",
            "\t grad:  2.0 4.0 -1.429399514307761e-07\n",
            "\t grad:  3.0 6.0 -2.9588569994132286e-07\n",
            "progress: 59 w=  1.9999999865207625 loss=  1.6352086111474931e-15\n",
            "\t grad:  1.0 2.0 -2.6958475007887728e-08\n",
            "\t grad:  2.0 4.0 -1.0567722164012139e-07\n",
            "\t grad:  3.0 6.0 -2.1875184863517916e-07\n",
            "progress: 60 w=  1.999999990034638 loss=  8.937759877335403e-16\n",
            "\t grad:  1.0 2.0 -1.993072418216002e-08\n",
            "\t grad:  2.0 4.0 -7.812843882959442e-08\n",
            "\t grad:  3.0 6.0 -1.617258700292723e-07\n",
            "progress: 61 w=  1.9999999926324883 loss=  4.885220495987371e-16\n",
            "\t grad:  1.0 2.0 -1.473502342363986e-08\n",
            "\t grad:  2.0 4.0 -5.7761292637792394e-08\n",
            "\t grad:  3.0 6.0 -1.195658771990793e-07\n",
            "progress: 62 w=  1.99999999455311 loss=  2.670175009618106e-16\n",
            "\t grad:  1.0 2.0 -1.0893780100218464e-08\n",
            "\t grad:  2.0 4.0 -4.270361841918202e-08\n",
            "\t grad:  3.0 6.0 -8.839649012770678e-08\n",
            "progress: 63 w=  1.9999999959730488 loss=  1.4594702493172377e-16\n",
            "\t grad:  1.0 2.0 -8.05390243385773e-09\n",
            "\t grad:  2.0 4.0 -3.1571296688071016e-08\n",
            "\t grad:  3.0 6.0 -6.53525820126788e-08\n",
            "progress: 64 w=  1.9999999970228268 loss=  7.977204100704301e-17\n",
            "\t grad:  1.0 2.0 -5.9543463493128e-09\n",
            "\t grad:  2.0 4.0 -2.334103754719763e-08\n",
            "\t grad:  3.0 6.0 -4.8315948575350376e-08\n",
            "progress: 65 w=  1.9999999977989402 loss=  4.360197735196887e-17\n",
            "\t grad:  1.0 2.0 -4.402119557767037e-09\n",
            "\t grad:  2.0 4.0 -1.725630838222969e-08\n",
            "\t grad:  3.0 6.0 -3.5720557178819945e-08\n",
            "progress: 66 w=  1.9999999983727301 loss=  2.3832065197304227e-17\n",
            "\t grad:  1.0 2.0 -3.254539748809293e-09\n",
            "\t grad:  2.0 4.0 -1.2757796596929438e-08\n",
            "\t grad:  3.0 6.0 -2.6408640607655798e-08\n",
            "progress: 67 w=  1.9999999987969397 loss=  1.3026183953845832e-17\n",
            "\t grad:  1.0 2.0 -2.406120636067044e-09\n",
            "\t grad:  2.0 4.0 -9.431992964437086e-09\n",
            "\t grad:  3.0 6.0 -1.9524227568012975e-08\n",
            "progress: 68 w=  1.999999999110563 loss=  7.11988308874388e-18\n",
            "\t grad:  1.0 2.0 -1.7788739370416806e-09\n",
            "\t grad:  2.0 4.0 -6.97318647269185e-09\n",
            "\t grad:  3.0 6.0 -1.4434496264925656e-08\n",
            "progress: 69 w=  1.9999999993424284 loss=  3.89160224698574e-18\n",
            "\t grad:  1.0 2.0 -1.3151431055291596e-09\n",
            "\t grad:  2.0 4.0 -5.155360582875801e-09\n",
            "\t grad:  3.0 6.0 -1.067159693945996e-08\n",
            "progress: 70 w=  1.9999999995138495 loss=  2.1270797208746147e-18\n",
            "\t grad:  1.0 2.0 -9.72300906454393e-10\n",
            "\t grad:  2.0 4.0 -3.811418736177075e-09\n",
            "\t grad:  3.0 6.0 -7.88963561149103e-09\n",
            "progress: 71 w=  1.9999999996405833 loss=  1.1626238773828175e-18\n",
            "\t grad:  1.0 2.0 -7.18833437218791e-10\n",
            "\t grad:  2.0 4.0 -2.8178277489132597e-09\n",
            "\t grad:  3.0 6.0 -5.832902161273523e-09\n",
            "progress: 72 w=  1.999999999734279 loss=  6.354692062078993e-19\n",
            "\t grad:  1.0 2.0 -5.314420015167798e-10\n",
            "\t grad:  2.0 4.0 -2.0832526814729135e-09\n",
            "\t grad:  3.0 6.0 -4.31233715403323e-09\n",
            "progress: 73 w=  1.9999999998035491 loss=  3.4733644793346653e-19\n",
            "\t grad:  1.0 2.0 -3.92901711165905e-10\n",
            "\t grad:  2.0 4.0 -1.5401742103904326e-09\n",
            "\t grad:  3.0 6.0 -3.188159070077745e-09\n",
            "progress: 74 w=  1.9999999998547615 loss=  1.8984796531526204e-19\n",
            "\t grad:  1.0 2.0 -2.9047697580608656e-10\n",
            "\t grad:  2.0 4.0 -1.1386696030513122e-09\n",
            "\t grad:  3.0 6.0 -2.3570478902001923e-09\n",
            "progress: 75 w=  1.9999999998926234 loss=  1.0376765851119951e-19\n",
            "\t grad:  1.0 2.0 -2.1475310418850313e-10\n",
            "\t grad:  2.0 4.0 -8.418314934033333e-10\n",
            "\t grad:  3.0 6.0 -1.7425900722400911e-09\n",
            "progress: 76 w=  1.9999999999206153 loss=  5.671751114309842e-20\n",
            "\t grad:  1.0 2.0 -1.5876944203796484e-10\n",
            "\t grad:  2.0 4.0 -6.223768167501476e-10\n",
            "\t grad:  3.0 6.0 -1.2883241140571045e-09\n",
            "progress: 77 w=  1.9999999999413098 loss=  3.100089617511693e-20\n",
            "\t grad:  1.0 2.0 -1.17380327679939e-10\n",
            "\t grad:  2.0 4.0 -4.601314884666863e-10\n",
            "\t grad:  3.0 6.0 -9.524754318590567e-10\n",
            "progress: 78 w=  1.9999999999566096 loss=  1.6944600977692705e-20\n",
            "\t grad:  1.0 2.0 -8.678080476443029e-11\n",
            "\t grad:  2.0 4.0 -3.4018121652934497e-10\n",
            "\t grad:  3.0 6.0 -7.041780492045291e-10\n",
            "progress: 79 w=  1.9999999999679208 loss=  9.2616919156479e-21\n",
            "\t grad:  1.0 2.0 -6.415845632545825e-11\n",
            "\t grad:  2.0 4.0 -2.5150193039280566e-10\n",
            "\t grad:  3.0 6.0 -5.206075570640678e-10\n",
            "progress: 80 w=  1.9999999999762834 loss=  5.062350511130293e-21\n",
            "\t grad:  1.0 2.0 -4.743316850408519e-11\n",
            "\t grad:  2.0 4.0 -1.8593837580738182e-10\n",
            "\t grad:  3.0 6.0 -3.8489211817704927e-10\n",
            "progress: 81 w=  1.999999999982466 loss=  2.7669155644059242e-21\n",
            "\t grad:  1.0 2.0 -3.5067948545020045e-11\n",
            "\t grad:  2.0 4.0 -1.3746692673066718e-10\n",
            "\t grad:  3.0 6.0 -2.845563784603655e-10\n",
            "progress: 82 w=  1.9999999999870368 loss=  1.5124150106147723e-21\n",
            "\t grad:  1.0 2.0 -2.5926372160256506e-11\n",
            "\t grad:  2.0 4.0 -1.0163070385260653e-10\n",
            "\t grad:  3.0 6.0 -2.1037571684701106e-10\n",
            "progress: 83 w=  1.999999999990416 loss=  8.26683933105326e-22\n",
            "\t grad:  1.0 2.0 -1.9167778475548403e-11\n",
            "\t grad:  2.0 4.0 -7.51381179497912e-11\n",
            "\t grad:  3.0 6.0 -1.5553425214420713e-10\n",
            "progress: 84 w=  1.9999999999929146 loss=  4.518126871054872e-22\n",
            "\t grad:  1.0 2.0 -1.4170886686315498e-11\n",
            "\t grad:  2.0 4.0 -5.555023108172463e-11\n",
            "\t grad:  3.0 6.0 -1.1499068364173581e-10\n",
            "progress: 85 w=  1.9999999999947617 loss=  2.469467919185614e-22\n",
            "\t grad:  1.0 2.0 -1.0476508549572827e-11\n",
            "\t grad:  2.0 4.0 -4.106759377009439e-11\n",
            "\t grad:  3.0 6.0 -8.500933290633839e-11\n",
            "progress: 86 w=  1.9999999999961273 loss=  1.349840097651456e-22\n",
            "\t grad:  1.0 2.0 -7.745359908994942e-12\n",
            "\t grad:  2.0 4.0 -3.036149109902908e-11\n",
            "\t grad:  3.0 6.0 -6.285105769165966e-11\n",
            "progress: 87 w=  1.999999999997137 loss=  7.376551550022107e-23\n",
            "\t grad:  1.0 2.0 -5.726086271806707e-12\n",
            "\t grad:  2.0 4.0 -2.2446045022661565e-11\n",
            "\t grad:  3.0 6.0 -4.646416584819235e-11\n",
            "progress: 88 w=  1.9999999999978835 loss=  4.031726170507742e-23\n",
            "\t grad:  1.0 2.0 -4.233058348290797e-12\n",
            "\t grad:  2.0 4.0 -1.659294923683774e-11\n",
            "\t grad:  3.0 6.0 -3.4351188560322043e-11\n",
            "progress: 89 w=  1.9999999999984353 loss=  2.2033851437431755e-23\n",
            "\t grad:  1.0 2.0 -3.1294966618133913e-12\n",
            "\t grad:  2.0 4.0 -1.226752033289813e-11\n",
            "\t grad:  3.0 6.0 -2.539835008974478e-11\n",
            "progress: 90 w=  1.9999999999988431 loss=  1.2047849775995315e-23\n",
            "\t grad:  1.0 2.0 -2.3137047833188262e-12\n",
            "\t grad:  2.0 4.0 -9.070078021977679e-12\n",
            "\t grad:  3.0 6.0 -1.8779644506139448e-11\n",
            "progress: 91 w=  1.9999999999991447 loss=  6.5840863393251405e-24\n",
            "\t grad:  1.0 2.0 -1.7106316363424412e-12\n",
            "\t grad:  2.0 4.0 -6.7057470687359455e-12\n",
            "\t grad:  3.0 6.0 -1.3882228699912957e-11\n",
            "progress: 92 w=  1.9999999999993676 loss=  3.5991747246272455e-24\n",
            "\t grad:  1.0 2.0 -1.2647660696529783e-12\n",
            "\t grad:  2.0 4.0 -4.957811938766099e-12\n",
            "\t grad:  3.0 6.0 -1.0263789818054647e-11\n",
            "progress: 93 w=  1.9999999999995324 loss=  1.969312363793734e-24\n",
            "\t grad:  1.0 2.0 -9.352518759442319e-13\n",
            "\t grad:  2.0 4.0 -3.666400516522117e-12\n",
            "\t grad:  3.0 6.0 -7.58859641791787e-12\n",
            "progress: 94 w=  1.9999999999996543 loss=  1.0761829795642296e-24\n",
            "\t grad:  1.0 2.0 -6.914468997365475e-13\n",
            "\t grad:  2.0 4.0 -2.7107205369247822e-12\n",
            "\t grad:  3.0 6.0 -5.611511255665391e-12\n",
            "progress: 95 w=  1.9999999999997444 loss=  5.875191475205477e-25\n",
            "\t grad:  1.0 2.0 -5.111466805374221e-13\n",
            "\t grad:  2.0 4.0 -2.0037305148434825e-12\n",
            "\t grad:  3.0 6.0 -4.1460168631601846e-12\n",
            "progress: 96 w=  1.999999999999811 loss=  3.2110109830478153e-25\n",
            "\t grad:  1.0 2.0 -3.779199175824033e-13\n",
            "\t grad:  2.0 4.0 -1.4814816040598089e-12\n",
            "\t grad:  3.0 6.0 -3.064215547965432e-12\n",
            "progress: 97 w=  1.9999999999998603 loss=  1.757455879087579e-25\n",
            "\t grad:  1.0 2.0 -2.793321129956894e-13\n",
            "\t grad:  2.0 4.0 -1.0942358130705543e-12\n",
            "\t grad:  3.0 6.0 -2.2648549702353193e-12\n",
            "progress: 98 w=  1.9999999999998967 loss=  9.608404711682446e-26\n",
            "\t grad:  1.0 2.0 -2.0650148258027912e-13\n",
            "\t grad:  2.0 4.0 -8.100187187665142e-13\n",
            "\t grad:  3.0 6.0 -1.6786572132332367e-12\n",
            "progress: 99 w=  1.9999999999999236 loss=  5.250973729513143e-26\n",
            "\t grad:  1.0 2.0 -1.5276668818842154e-13\n",
            "\t grad:  2.0 4.0 -5.986322548778844e-13\n",
            "\t grad:  3.0 6.0 -1.2363443602225743e-12\n",
            "progress: 100 w=  1.9999999999999436 loss=  2.8477878678478526e-26\n",
            "\t grad:  1.0 2.0 -1.127986593019159e-13\n",
            "\t grad:  2.0 4.0 -4.4231285301066237e-13\n",
            "\t grad:  3.0 6.0 -9.166001291305292e-13\n",
            "progress: 101 w=  1.9999999999999583 loss=  1.5683343656698936e-26\n",
            "\t grad:  1.0 2.0 -8.348877145181177e-14\n",
            "\t grad:  2.0 4.0 -3.268496584496461e-13\n",
            "\t grad:  3.0 6.0 -6.767919558114954e-13\n",
            "progress: 102 w=  1.9999999999999691 loss=  8.532319550870464e-27\n",
            "\t grad:  1.0 2.0 -6.17284001691587e-14\n",
            "\t grad:  2.0 4.0 -2.4158453015843406e-13\n",
            "\t grad:  3.0 6.0 -5.009326287108706e-13\n",
            "progress: 103 w=  1.9999999999999774 loss=  4.556460588556564e-27\n",
            "\t grad:  1.0 2.0 -4.529709940470639e-14\n",
            "\t grad:  2.0 4.0 -1.7763568394002505e-13\n",
            "\t grad:  3.0 6.0 -3.6770586575585185e-13\n",
            "progress: 104 w=  1.9999999999999833 loss=  2.473867798773093e-27\n",
            "\t grad:  1.0 2.0 -3.3306690738754696e-14\n",
            "\t grad:  2.0 4.0 -1.3145040611561853e-13\n",
            "\t grad:  3.0 6.0 -2.717825964282383e-13\n",
            "progress: 105 w=  1.9999999999999876 loss=  1.3915506368098648e-27\n",
            "\t grad:  1.0 2.0 -2.4868995751603507e-14\n",
            "\t grad:  2.0 4.0 -9.769962616701378e-14\n",
            "\t grad:  3.0 6.0 -2.0250467969162855e-13\n",
            "progress: 106 w=  1.9999999999999907 loss=  8.077935669463161e-28\n",
            "\t grad:  1.0 2.0 -1.865174681370263e-14\n",
            "\t grad:  2.0 4.0 -7.283063041541027e-14\n",
            "\t grad:  3.0 6.0 -1.4921397450962104e-13\n",
            "progress: 107 w=  1.9999999999999931 loss=  4.1730741886191525e-28\n",
            "\t grad:  1.0 2.0 -1.3766765505351941e-14\n",
            "\t grad:  2.0 4.0 -5.3290705182007514e-14\n",
            "\t grad:  3.0 6.0 -1.1191048088221578e-13\n",
            "progress: 108 w=  1.999999999999995 loss=  2.279808016088724e-28\n",
            "\t grad:  1.0 2.0 -1.021405182655144e-14\n",
            "\t grad:  2.0 4.0 -4.085620730620576e-14\n",
            "\t grad:  3.0 6.0 -8.526512829121202e-14\n",
            "progress: 109 w=  1.9999999999999962 loss=  1.33317492982351e-28\n",
            "\t grad:  1.0 2.0 -7.549516567451064e-15\n",
            "\t grad:  2.0 4.0 -3.019806626980426e-14\n",
            "\t grad:  3.0 6.0 -6.394884621840902e-14\n",
            "progress: 110 w=  1.9999999999999971 loss=  7.888609052210118e-29\n",
            "\t grad:  1.0 2.0 -5.773159728050814e-15\n",
            "\t grad:  2.0 4.0 -2.3092638912203256e-14\n",
            "\t grad:  3.0 6.0 -4.796163466380676e-14\n",
            "progress: 111 w=  1.9999999999999978 loss=  5.048709793414476e-29\n",
            "\t grad:  1.0 2.0 -4.440892098500626e-15\n",
            "\t grad:  2.0 4.0 -1.7763568394002505e-14\n",
            "\t grad:  3.0 6.0 -3.730349362740526e-14\n",
            "progress: 112 w=  1.9999999999999984 loss=  1.9721522630525295e-29\n",
            "\t grad:  1.0 2.0 -3.1086244689504383e-15\n",
            "\t grad:  2.0 4.0 -1.2434497875801753e-14\n",
            "\t grad:  3.0 6.0 -2.1316282072803006e-14\n",
            "progress: 113 w=  1.999999999999999 loss=  1.262177448353619e-29\n",
            "\t grad:  1.0 2.0 -2.220446049250313e-15\n",
            "\t grad:  2.0 4.0 -8.881784197001252e-15\n",
            "\t grad:  3.0 6.0 -2.1316282072803006e-14\n",
            "progress: 114 w=  1.9999999999999991 loss=  7.099748146989106e-30\n",
            "\t grad:  1.0 2.0 -1.7763568394002505e-15\n",
            "\t grad:  2.0 4.0 -7.105427357601002e-15\n",
            "\t grad:  3.0 6.0 -1.5987211554602254e-14\n",
            "progress: 115 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 116 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 117 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 118 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 119 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 120 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 121 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 122 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 123 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 124 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 125 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 126 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 127 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 128 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 129 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 130 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 131 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 132 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 133 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 134 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 135 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 136 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 137 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 138 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 139 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 140 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 141 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 142 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 143 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 144 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 145 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 146 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 147 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 148 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 149 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 150 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 151 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 152 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 153 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 154 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 155 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 156 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 157 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 158 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 159 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 160 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 161 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 162 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 163 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 164 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 165 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 166 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 167 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 168 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 169 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 170 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 171 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 172 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 173 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 174 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 175 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 176 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 177 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 178 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 179 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 180 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 181 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 182 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 183 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 184 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 185 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 186 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 187 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 188 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 189 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 190 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 191 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 192 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 193 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 194 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 195 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 196 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 197 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 198 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "\t grad:  1.0 2.0 -1.3322676295501878e-15\n",
            "\t grad:  2.0 4.0 -5.329070518200751e-15\n",
            "\t grad:  3.0 6.0 -1.0658141036401503e-14\n",
            "progress: 199 w=  1.9999999999999993 loss=  3.1554436208840472e-30\n",
            "predict (after training) 4hours 7.999999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4z3zlNZFwVO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}