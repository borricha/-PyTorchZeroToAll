{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWDnHY5OaVt11RvvhYfmrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borricha/-PyTorchZeroToAll/blob/main/lec_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ_3DdC1ObWd",
        "outputId": "67acf100-3c42-4a81-e4be-7be681abea76"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
        "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.linear = torch.nn.Linear(1,1) # one in and one out\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pred = self.linear(x)\n",
        "    return y_pred\n",
        "\n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.MSELoss(size_average = False)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "#Training\n",
        "for epoch in range(300):\n",
        "  #Forward Pass\n",
        "  y_pred = model(x_data)\n",
        "\n",
        "  #compute loss\n",
        "  loss = criterion(y_pred, y_data)\n",
        "  print(epoch, loss.item())\n",
        "\n",
        "  #Zero gradient, perform backward\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "hour_var = Variable(torch.Tensor([4.0]))\n",
        "print(\"predict (after training)\", 4, model.forward(hour_var).item())\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 153.6374053955078\n",
            "1 68.41476440429688\n",
            "2 30.475784301757812\n",
            "3 13.58614444732666\n",
            "4 6.067083358764648\n",
            "5 2.719540596008301\n",
            "6 1.2290396690368652\n",
            "7 0.5652486085891724\n",
            "8 0.26948612928390503\n",
            "9 0.13756480813026428\n",
            "10 0.07858411967754364\n",
            "11 0.0520784929394722\n",
            "12 0.0400332547724247\n",
            "13 0.034428805112838745\n",
            "14 0.03169528394937515\n",
            "15 0.03024306148290634\n",
            "16 0.02936478704214096\n",
            "17 0.028745245188474655\n",
            "18 0.02824421040713787\n",
            "19 0.027799174189567566\n",
            "20 0.027382131665945053\n",
            "21 0.02698092721402645\n",
            "22 0.02658975124359131\n",
            "23 0.026206063106656075\n",
            "24 0.025828804820775986\n",
            "25 0.025457197800278664\n",
            "26 0.025091230869293213\n",
            "27 0.02473062090575695\n",
            "28 0.02437509223818779\n",
            "29 0.0240248404443264\n",
            "30 0.02367956005036831\n",
            "31 0.023339180275797844\n",
            "32 0.02300385758280754\n",
            "33 0.022673191502690315\n",
            "34 0.022347381338477135\n",
            "35 0.022026188671588898\n",
            "36 0.02170959860086441\n",
            "37 0.021397581323981285\n",
            "38 0.02109014242887497\n",
            "39 0.020786967128515244\n",
            "40 0.02048826776444912\n",
            "41 0.020193777978420258\n",
            "42 0.019903535023331642\n",
            "43 0.01961756870150566\n",
            "44 0.01933566853404045\n",
            "45 0.019057728350162506\n",
            "46 0.018783871084451675\n",
            "47 0.01851394772529602\n",
            "48 0.01824786514043808\n",
            "49 0.01798558048903942\n",
            "50 0.01772710494697094\n",
            "51 0.017472323030233383\n",
            "52 0.01722126081585884\n",
            "53 0.016973737627267838\n",
            "54 0.016729794442653656\n",
            "55 0.01648932695388794\n",
            "56 0.016252407804131508\n",
            "57 0.016018765047192574\n",
            "58 0.015788646414875984\n",
            "59 0.015561679378151894\n",
            "60 0.015338050201535225\n",
            "61 0.015117631293833256\n",
            "62 0.014900334179401398\n",
            "63 0.014686210080981255\n",
            "64 0.014475139789283276\n",
            "65 0.014267109334468842\n",
            "66 0.014062055386602879\n",
            "67 0.013859998434782028\n",
            "68 0.013660816475749016\n",
            "69 0.013464486226439476\n",
            "70 0.01327101793140173\n",
            "71 0.01308025885373354\n",
            "72 0.01289224810898304\n",
            "73 0.01270698755979538\n",
            "74 0.012524310499429703\n",
            "75 0.01234437059611082\n",
            "76 0.012166919186711311\n",
            "77 0.011992089450359344\n",
            "78 0.011819764971733093\n",
            "79 0.01164985354989767\n",
            "80 0.011482457630336285\n",
            "81 0.011317397467792034\n",
            "82 0.011154785752296448\n",
            "83 0.01099451445043087\n",
            "84 0.010836455971002579\n",
            "85 0.010680756531655788\n",
            "86 0.010527239181101322\n",
            "87 0.010375946760177612\n",
            "88 0.010226789861917496\n",
            "89 0.010079869069159031\n",
            "90 0.009934956207871437\n",
            "91 0.009792196564376354\n",
            "92 0.00965146441012621\n",
            "93 0.009512776508927345\n",
            "94 0.009376050904393196\n",
            "95 0.00924128107726574\n",
            "96 0.009108468890190125\n",
            "97 0.008977577090263367\n",
            "98 0.008848534896969795\n",
            "99 0.008721388876438141\n",
            "100 0.00859605148434639\n",
            "101 0.00847250409424305\n",
            "102 0.008350765332579613\n",
            "103 0.008230735547840595\n",
            "104 0.008112465031445026\n",
            "105 0.00799582526087761\n",
            "106 0.007880963385105133\n",
            "107 0.007767677307128906\n",
            "108 0.007656059693545103\n",
            "109 0.007546058390289545\n",
            "110 0.007437529973685741\n",
            "111 0.0073306988924741745\n",
            "112 0.007225322537124157\n",
            "113 0.007121464237570763\n",
            "114 0.00701913284137845\n",
            "115 0.00691826269030571\n",
            "116 0.006818847265094519\n",
            "117 0.006720856763422489\n",
            "118 0.006624280940741301\n",
            "119 0.006529080681502819\n",
            "120 0.006435221992433071\n",
            "121 0.0063427286222577095\n",
            "122 0.006251607555896044\n",
            "123 0.006161707919090986\n",
            "124 0.006073188502341509\n",
            "125 0.005985907278954983\n",
            "126 0.0058998484164476395\n",
            "127 0.00581509480252862\n",
            "128 0.005731496028602123\n",
            "129 0.005649127531796694\n",
            "130 0.005567945074290037\n",
            "131 0.005487923044711351\n",
            "132 0.005409061908721924\n",
            "133 0.0053313360549509525\n",
            "134 0.005254716612398624\n",
            "135 0.005179174710065126\n",
            "136 0.005104748532176018\n",
            "137 0.005031377077102661\n",
            "138 0.004959118086844683\n",
            "139 0.0048878369852900505\n",
            "140 0.004817584063857794\n",
            "141 0.00474835280328989\n",
            "142 0.004680096171796322\n",
            "143 0.004612870514392853\n",
            "144 0.004546554759144783\n",
            "145 0.004481193609535694\n",
            "146 0.004416804760694504\n",
            "147 0.004353334195911884\n",
            "148 0.004290745593607426\n",
            "149 0.004229128360748291\n",
            "150 0.004168306011706591\n",
            "151 0.00410843500867486\n",
            "152 0.004049363080412149\n",
            "153 0.003991170786321163\n",
            "154 0.003933819010853767\n",
            "155 0.0038772912230342627\n",
            "156 0.003821564605459571\n",
            "157 0.00376662309281528\n",
            "158 0.003712497651576996\n",
            "159 0.0036591608077287674\n",
            "160 0.0036065978929400444\n",
            "161 0.003554730676114559\n",
            "162 0.0035036522895097733\n",
            "163 0.003453298471868038\n",
            "164 0.003403685986995697\n",
            "165 0.0033547321800142527\n",
            "166 0.0033065439201891422\n",
            "167 0.0032590199261903763\n",
            "168 0.003212162759155035\n",
            "169 0.003166001522913575\n",
            "170 0.0031205022241920233\n",
            "171 0.0030756648629903793\n",
            "172 0.003031461965292692\n",
            "173 0.0029879098292440176\n",
            "174 0.0029449600260704756\n",
            "175 0.002902618609368801\n",
            "176 0.0028609165456146\n",
            "177 0.0028197942301630974\n",
            "178 0.0027792882174253464\n",
            "179 0.002739321906119585\n",
            "180 0.0026999651454389095\n",
            "181 0.0026611601933836937\n",
            "182 0.0026229252107441425\n",
            "183 0.002585232723504305\n",
            "184 0.0025480506010353565\n",
            "185 0.0025114468298852444\n",
            "186 0.002475342247635126\n",
            "187 0.0024397806264460087\n",
            "188 0.0024047098122537136\n",
            "189 0.002370145171880722\n",
            "190 0.0023360862396657467\n",
            "191 0.0023024999536573887\n",
            "192 0.0022694142535328865\n",
            "193 0.002236821223050356\n",
            "194 0.0022046822123229504\n",
            "195 0.002172970911487937\n",
            "196 0.002141745062544942\n",
            "197 0.0021109720692038536\n",
            "198 0.002080620964989066\n",
            "199 0.0020507394801825285\n",
            "200 0.002021275693550706\n",
            "201 0.001992211677134037\n",
            "202 0.0019635800272226334\n",
            "203 0.0019353574607521296\n",
            "204 0.001907532219775021\n",
            "205 0.0018801328260451555\n",
            "206 0.0018531219102442265\n",
            "207 0.0018264655955135822\n",
            "208 0.0018002341967076063\n",
            "209 0.001774366246536374\n",
            "210 0.0017488583689555526\n",
            "211 0.0017237282590940595\n",
            "212 0.0016989356372505426\n",
            "213 0.0016745248576626182\n",
            "214 0.0016504705417901278\n",
            "215 0.0016267400933429599\n",
            "216 0.0016033584251999855\n",
            "217 0.001580307842232287\n",
            "218 0.0015576215228065848\n",
            "219 0.0015352405607700348\n",
            "220 0.0015131729887798429\n",
            "221 0.0014914312632754445\n",
            "222 0.0014699962921440601\n",
            "223 0.0014488670276477933\n",
            "224 0.0014280357863754034\n",
            "225 0.0014075341168791056\n",
            "226 0.0013872955460101366\n",
            "227 0.0013673497596755624\n",
            "228 0.0013477106112986803\n",
            "229 0.0013283342123031616\n",
            "230 0.0013092412846162915\n",
            "231 0.0012904307805001736\n",
            "232 0.0012718889629468322\n",
            "233 0.0012536130379885435\n",
            "234 0.0012355819344520569\n",
            "235 0.0012178253382444382\n",
            "236 0.0012003122828900814\n",
            "237 0.0011830638395622373\n",
            "238 0.0011660753516480327\n",
            "239 0.0011493240017443895\n",
            "240 0.0011328113032504916\n",
            "241 0.0011165114119648933\n",
            "242 0.001100481953471899\n",
            "243 0.0010846545919775963\n",
            "244 0.001069071120582521\n",
            "245 0.0010537117486819625\n",
            "246 0.0010385609930381179\n",
            "247 0.001023629680275917\n",
            "248 0.0010089228162541986\n",
            "249 0.0009944140911102295\n",
            "250 0.0009801178239285946\n",
            "251 0.000966053397860378\n",
            "252 0.000952153408434242\n",
            "253 0.0009384716977365315\n",
            "254 0.0009249827708117664\n",
            "255 0.0009116844739764929\n",
            "256 0.0008985905442386866\n",
            "257 0.0008856778731569648\n",
            "258 0.000872946111485362\n",
            "259 0.0008604106842540205\n",
            "260 0.0008480251999571919\n",
            "261 0.0008358504856005311\n",
            "262 0.0008238473092205822\n",
            "263 0.000812003796454519\n",
            "264 0.0008003332186490297\n",
            "265 0.0007888336549513042\n",
            "266 0.0007774871191941202\n",
            "267 0.0007663063588552177\n",
            "268 0.0007553072646260262\n",
            "269 0.0007444575312547386\n",
            "270 0.0007337539573200047\n",
            "271 0.0007231983472593129\n",
            "272 0.0007128044962882996\n",
            "273 0.0007025753147900105\n",
            "274 0.0006924629560671747\n",
            "275 0.0006825179443694651\n",
            "276 0.0006727128056809306\n",
            "277 0.0006630445132032037\n",
            "278 0.0006535027059726417\n",
            "279 0.0006441288278438151\n",
            "280 0.0006348667084239423\n",
            "281 0.0006257472559809685\n",
            "282 0.0006167442770674825\n",
            "283 0.0006078739534132183\n",
            "284 0.0005991447251290083\n",
            "285 0.0005905281286686659\n",
            "286 0.0005820496589876711\n",
            "287 0.0005736825987696648\n",
            "288 0.0005654397537000477\n",
            "289 0.0005573183298110962\n",
            "290 0.0005493060452863574\n",
            "291 0.0005414113402366638\n",
            "292 0.0005336328176781535\n",
            "293 0.000525951967574656\n",
            "294 0.0005183956236578524\n",
            "295 0.0005109570338390768\n",
            "296 0.0005036061047576368\n",
            "297 0.000496369379106909\n",
            "298 0.0004892402794212103\n",
            "299 0.0004822125774808228\n",
            "predict (after training) 4 7.974757194519043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_LK7rBRXm7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}